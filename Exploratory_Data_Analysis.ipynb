{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{data_path}train_phase_1.csv')\n",
    "data.date = pd.to_datetime(data.date, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "test = pd.read_csv(f'{data_path}test_phase_1.csv')\n",
    "test.date = pd.to_datetime(test.date, format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check that this data has the exact types we are waiting for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.dtypes.equals(pd.Series({\n",
    "    'date': 'datetime64[ns]', \n",
    "    'wp1': 'float64', \n",
    "    'u': 'float64', \n",
    "    'v': 'float64', \n",
    "    'ws': 'float64', \n",
    "    'wd': 'float64',\n",
    "}))\n",
    "\n",
    "assert test.dtypes.equals(pd.Series({\n",
    "    'date': 'datetime64[ns]', \n",
    "    'u': 'float64', \n",
    "    'v': 'float64', \n",
    "    'ws': 'float64', \n",
    "    'wd': 'float64',\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we check that we have no NA values in the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not data.isnull().any(axis=None) and not test.isnull().any(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, our data is exactly the types we want, and no NA are present, we can pass on to an exploratory data analysis (EDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and first models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by checking what we want to predict : the power measurement wp1 of the first farm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.head(300).date, data.head(300).wp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.wp1.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.wp1.min(), data.wp1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Critical parameter in predicting the wind power, obviously seems to be the wind speed. Let us observe this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.head(300).date, data.head(300).ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there is any correlation between power and speed by taking a look at one of them, function of the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(data.head(300).ws, data.head(300).wp1)\n",
    "plt.xlabel('windspeed')\n",
    "plt.ylabel('windpower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There clearly seems to be a correlation between the two ! When windspeed rises, the wind power rises, on average, even if the relation between the two is not linear. \n",
    "\n",
    "We can confirm this by calculating the correlation coeficient betwen the two. Actually we can directly calculate all of the correlation coefficient between all variables in the dataset in one line of code. Let us do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient between windpseed and wind powe is 0.7 : this is very high indeed, our firt conclusion were true. Let us recall Pearson's definition of correlation, which is the one we used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sample, it is defined by : \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\sum \\limits _{i=1} ^{n} (x_{i} - \\bar x) (y_{i} - \\bar y)}{\\sqrt{\\sum \\limits _{i=1} ^{n}(x_{i} - \\bar x)^{2}}\\sqrt{\\sum \\limits _{i=1} ^{n}(y_{i} - \\bar y)^{2}}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is important to recall is that it is comprised in the range $[-1, 1]$ and : \n",
    "    - it is equal to 1 if the two variables are exactly the same\n",
    "    - -1 if the two varables are the exact opposite\n",
    "    - when it is equal to 0, the two variables have nothing in common : they are independent one from the other, for example this could be the value of the bitcoin and the average windspeed in south korea, we know these two have nothing in common.\n",
    "    - when it is > 0, the two variables are positively correlated, this means that on average, when one goes up, the other goes up too.\n",
    "    - when it is < 0, the two variables are negatively correlated, this means that on average, when one goes up, the other goes down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this first EDA, a very simple model we can try to predict our sample is to try a linear model : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ wp_{1} = \\alpha . ws + \\beta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do so, we import some libraries that will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now cut our dataframe in two : one dataframe will be used for training, and the other one will be used to estimate what is the value of this first model we have made. \n",
    "For this, why do we not directly use the test set ? The reason is that for the test set, we do not know the exact value of the power measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, test_size=0.2, shuffle=True)\n",
    "print(train.shape, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['ws'].values.reshape((-1, 1))\n",
    "y_train = train['wp1'].values\n",
    "\n",
    "X_val = val['ws'].values.reshape((-1, 1))\n",
    "y_val = val['wp1'].values\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "mean_absolute_error(lm.predict(X_val), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice ! We have our first model and it gives an error of 0.13 !..\n",
    "\n",
    "Now wait, what is the value of that first model ? How can we know if 0.13 is actually a good error ? Well for this, a very neat way to be able to know if our model is worth anything is to compare it to a naive model. A naive model can be for example to predict everytime the same value, whatever the conditions. One of these naive model we have at hand would be to predict the mean value of the wind power in the train set. Let's see what would this model give. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DummyRegressor(strategy='mean')\n",
    "dm.fit(X_train, y_train)\n",
    "print(mean_absolute_error(dm.predict(X_val), y_val))\n",
    "\n",
    "dm = DummyRegressor(strategy='median')\n",
    "dm.fit(X_train, y_train)\n",
    "print(mean_absolute_error(dm.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes ! Good news, our model did really learn something good ! We are a lot better than the 'mean' or 'median' model, around 30% better, based on this metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wind direction, u & v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.head(300).date, data.head(300).wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to see that, as expected, it is comprised between 0 and 360. And when it crosses 360 it goes to 0, as expected for a direction. But this makes it a highly discontinuous function in 360. How should we treat this in the models ? That's a question for you to answer.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing about direction, the wind vector can be either expressed as : \n",
    "    - windspeed, and wind direction, \n",
    "    - or u and v components. \n",
    "These two representations are interchangeable (for math guys, there is a bijection between these two representations)\n",
    "And in our case, the convention for the wind direction used in our data is wind vector azimuth. For more information on these matters, please check the following website which explains these representations : \n",
    "    http://tornado.sfsu.edu/geosciences/classes/m430/Wind/WindDirection.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.head(300).date, data.head(300).u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(data.head(300).date, data.head(300).v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen first models above : the linear model with one variable (windspeed), and two naive models (median, and mean). It will be your job from now on to determine the best model, but let's already take a look at one classic model that data scientists usually try on for nearly any subject : Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['ws', 'wd', 'u', 'v']].values\n",
    "y_train = train['wp1'].values\n",
    "\n",
    "X_val = val[['ws', 'wd', 'u', 'v']].values\n",
    "y_val = val['wp1'].values\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "print(mean_absolute_error(rf.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest does only very slightly better than the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model is fit, we can pass on to the predictions.\n",
    "\n",
    "_Note: be careful when generating your submission file. Indeed, it needs to be a csv file with \";\" as separator._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[['ws', 'wd', 'u', 'v']].values\n",
    "\n",
    "df_predictions = pd.DataFrame({\n",
    "    'date': test['date'],\n",
    "    'wp1': rf.predict(X_test),\n",
    "})\n",
    "\n",
    "df_predictions.to_csv('predictions.csv', index=False, sep=';')\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is your turn, what better model can you think of ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
